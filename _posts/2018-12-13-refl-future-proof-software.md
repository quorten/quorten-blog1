---
layout: post
title: Reflections on future-proof software
date: 2018-12-13 12:26 -0600
author: quorten
categories: [tour-de-force, reiterate]
tags: [tour-de-force, reiterate]
---

Again, I reiterate, because this is important!  Many times I wonder if
there is a single software platform that you can place your bets in of
it being compatible with your higher level software and data for years
to come.  Indeed, Unix-like systems are about as close as you can get
to this ideal, as they have both been around for a very long time and
have been very resistent to compatibility breaking changes, even those
that would add an important feature.  Linux, though being a little
less conservative, is still very strong in its Unix roots of
resistance to change.

But, the bigger lesson to be learned is this.  Time and time again,
throughout the history of computer software, we observe that there is
some old and well-established software project that seems to be pretty
stable, but then an up and coming forerunner comes totally out of the
blue.  They start out with a small development team and a very weak
technical code base, but they have a technical advantage simply
through their development methodology that allows them to grow much
faster than the old incumbent established players ever have.  Pretty
soon, this higher growth rate causes the new project to completely
eclipse the old project in a fraction of time so small as to be
unimaginable to the original old project developers.  Current users of
the old project switch over to the compelling new project, despite the
obstacles, difficulties, and transition costs.  The developers of the
old project try to adapt to catch the wind of the pace of the new
project, but no matter what they try to do, they can't seem to keep
up.  Finally, the developers of the old project just quit and tell
anyone in their existing user base to switch to the new project that
has since replaced them.

<!-- more -->

When you think even deeper about these predicaments that have been
observed in the software world, _indeed, it is really curious_.  Why
is it that we haven't really observed likewise in the hardware world?
Sure, there are some hardware companies that have stuck to
old-fashioned methodologies until they fell out of business, but there
are also many hardware companies that have a long history of
successfully migrating to new hardware technologies as they become
available.

It's hard for me to draw a conclusion on this, but I think it's
because of the very founding fact that separates hardware and software
development.  Hardware companies are very light on design and
engineering.  Not only most of the revenue comes from manufacturing,
but this is also where most of the total human work is being
performed.  In the software world, there is virtually no human work
that can be done on "manufacturing": It's all in the design and
engineering.  For this reason, you would be led to believe that any
mistakes in design and engineering in the software world would have a
much more detrimental effect on a company's viability than in the
hardware world.  Still, this is really interesting to think about
given that design blunders in the hardware world can have major
detriments in a company too.  Yet, despite this fact, I'm claiming
that for hardware, a major hardware mistake is "insignificant"
compared to a major software mistake?
